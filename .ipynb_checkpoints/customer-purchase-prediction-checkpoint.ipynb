{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d0bcede-0826-475c-8678-72835c042b37",
   "metadata": {},
   "source": [
    "Customer Purchase Prediction\n",
    "\n",
    "RetailTech Solutions is a fast-growing international e-commerce platform operating in over 20 countries across Europe, North America, and Asia. They specialize in fashion, electronics, and home goods, with a unique business model that combines traditional retail with a marketplace for independent sellers.\n",
    "\n",
    "The company has seen rapid growth. A key part of their success has been their data-driven approach to personalization. However, as they plan their expansion into new markets, they need to improve their ability to predict customer behavior.\n",
    "\n",
    "Their marketing team wants to predict which customers are most likely to make a purchase based on their browsing behavior. We will help build this prediction system and our work will directly impact RetailTech's growth strategy and their goal of increasing revenue.\n",
    "\n",
    "\n",
    "## Data Description\n",
    "\n",
    "| Column Name | Criteria |\n",
    "|------------|----------|\n",
    "| customer_id | Integer. Unique identifier for each customer. No missing values. |\n",
    "| time_spent | Float. Minutes spent on website per session. Missing values should be replaced with median. |\n",
    "| pages_viewed | Integer. Number of pages viewed in session. Missing values should be replaced with mean. |\n",
    "| basket_value | Float. Value of items in basket. Missing values should be replaced with 0. |\n",
    "| device_type | String. One of: Mobile, Desktop, Tablet. Missing values should be replaced with \"Unknown\". |\n",
    "| customer_type | String. One of: New, Returning. Missing values should be replaced with \"New\". |\n",
    "| purchase | Binary. Whether customer made a purchase (1) or not (0). Target variable. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5a3bb-bbae-4d39-a6c6-daa46c470347",
   "metadata": {
    "tags": []
   },
   "source": [
    "The marketing team has collected customer session data in `raw_customer_data.csv`, but it contains missing values and inconsistencies that need to be addressed.\n",
    "Create a cleaned version of the dataframe:\n",
    "\n",
    "- Start with the data in the file `raw_customer_data.csv`\n",
    "- Your output should be a DataFrame named `clean_data`\n",
    "- All column names and values should match the table below.\n",
    "</br>\n",
    "\n",
    "| Column Name | Criteria |\n",
    "|------------|----------|\n",
    "| customer_id | Integer. Unique identifier for each customer. No missing values. |\n",
    "| time_spent | Float. Minutes spent on website per session. Missing values should be replaced with median. |\n",
    "| pages_viewed | Integer. Number of pages viewed in session. Missing values should be replaced with mean. |\n",
    "| basket_value | Float. Value of items in basket. Missing values should be replaced with 0. |\n",
    "| device_type | String. One of: Mobile, Desktop, Tablet. Missing values should be replaced with \"Unknown\". |\n",
    "| customer_type | String. One of: New, Returning. Missing values should be replaced with \"New\". |\n",
    "| purchase | Binary. Whether customer made a purchase (1) or not (0). Target variable. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce18b54-29af-4beb-bc8c-79c4e21bcd52",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 46,
    "lastExecutedAt": 1748190888899,
    "lastExecutedByKernel": "d5bdc7bd-74a9-4a6d-987f-4fea89fe299a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Write your answer to Task 1 here \nimport pandas as pd\n\nclean_data = pd.read_csv('raw_customer_data.csv')\n\n\n#time_spent\nclean_data['time_spent'] = clean_data['time_spent'].fillna(round(clean_data['time_spent'].median(),2))\n\n#pages_viewed\nclean_data['pages_viewed'] = clean_data['pages_viewed'].fillna(round(clean_data['pages_viewed'].mean(),2))\nclean_data['pages_viewed'] = clean_data['pages_viewed'].astype(int)\n\n#basket_value\nclean_data['basket_value'] = clean_data['basket_value'].fillna(0)\n\n#device_type\nclean_data['device_type'] = clean_data['device_type'].fillna('Unknown')\n\n#customer_type\nclean_data['customer_type'] = clean_data['customer_type'].fillna('New')\n\n#purchase\nclean_data['purchase'] = clean_data['purchase'].astype(bool)\n\n#clean_data.isna().sum()\nclean_data.dtypes\n\n#clean_data['purchase'].value_counts()",
    "outputsMetadata": {
     "0": {
      "height": 50,
      "tableState": {
       "customFilter": {
        "const": {
         "type": "boolean",
         "valid": true,
         "value": true
        },
        "id": "f2ba990a-3eda-4179-b495-f929cf31e7eb",
        "nodeType": "const"
       }
      },
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id        int64\n",
       "time_spent       float64\n",
       "pages_viewed       int32\n",
       "basket_value     float64\n",
       "device_type       object\n",
       "customer_type     object\n",
       "purchase            bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clean_data = pd.read_csv('raw_customer_data.csv')\n",
    "\n",
    "\n",
    "#time_spent\n",
    "clean_data['time_spent'] = clean_data['time_spent'].fillna(round(clean_data['time_spent'].median(),2))\n",
    "\n",
    "#pages_viewed\n",
    "clean_data['pages_viewed'] = clean_data['pages_viewed'].fillna(round(clean_data['pages_viewed'].mean(),2))\n",
    "clean_data['pages_viewed'] = clean_data['pages_viewed'].astype(int)\n",
    "\n",
    "#basket_value\n",
    "clean_data['basket_value'] = clean_data['basket_value'].fillna(0)\n",
    "\n",
    "#device_type\n",
    "clean_data['device_type'] = clean_data['device_type'].fillna('Unknown')\n",
    "\n",
    "#customer_type\n",
    "clean_data['customer_type'] = clean_data['customer_type'].fillna('New')\n",
    "\n",
    "#purchase\n",
    "clean_data['purchase'] = clean_data['purchase'].astype(bool)\n",
    "\n",
    "#clean_data.isna().sum()\n",
    "clean_data.dtypes\n",
    "\n",
    "#clean_data['purchase'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b3c30-d3b0-4762-ae10-0f2880873bdc",
   "metadata": {},
   "source": [
    "The pre-cleaned dataset `model_data.csv` needs to be prepared for our neural network.\n",
    "Create the model features:\n",
    "\n",
    "- Start with the data in the file `model_data.csv`\n",
    "- Scale numerical features (`time_spent`, `pages_viewed`, `basket_value`) to 0-1 range\n",
    "- Apply one-hot encoding to the categorical features (`device_type`, `customer_type`)\n",
    "    - The column names should have the following format: variable_name_category_name (e.g., `device_type_Desktop`)\n",
    "- Your output should be a DataFrame named `model_feature_set`, with all column names from `model_data.csv` except for the columns where one-hot encoding was applied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d47e440-c4ab-45cf-af40-53181764bac4",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 50,
    "lastExecutedAt": 1748190888949,
    "lastExecutedByKernel": "d5bdc7bd-74a9-4a6d-987f-4fea89fe299a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Write your answer to Task 2 here\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\n# Standardize Features\ndf = pd.read_csv(\"model_data.csv\")\ncolumns = ['time_spent', 'pages_viewed', 'basket_value']\n\nfor column in columns:\n    df[column] = scaler.fit_transform(df[[column]])\n\n# One-hot encoding\noriginal_cols = df.columns\ndf_encoded = pd.get_dummies(df, columns=['device_type'])\nmodel_feature_set = pd.get_dummies(df_encoded, columns=['customer_type'])\n\n\nmodel_feature_set.head()\n",
    "outputsMetadata": {
     "0": {
      "height": 550,
      "tableState": {
       "customFilter": {
        "const": {
         "type": "boolean",
         "valid": true,
         "value": true
        },
        "id": "dedcf454-91b5-4ba6-b62d-77a1bba857cc",
        "nodeType": "const"
       }
      },
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>pages_viewed</th>\n",
       "      <th>basket_value</th>\n",
       "      <th>purchase</th>\n",
       "      <th>device_type_Desktop</th>\n",
       "      <th>device_type_Mobile</th>\n",
       "      <th>device_type_Tablet</th>\n",
       "      <th>device_type_Unknown</th>\n",
       "      <th>customer_type_New</th>\n",
       "      <th>customer_type_Returning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501</td>\n",
       "      <td>0.682273</td>\n",
       "      <td>-0.038919</td>\n",
       "      <td>-1.339318</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>502</td>\n",
       "      <td>0.040076</td>\n",
       "      <td>-1.011895</td>\n",
       "      <td>0.938511</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>503</td>\n",
       "      <td>-0.857722</td>\n",
       "      <td>-1.401086</td>\n",
       "      <td>0.644815</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>504</td>\n",
       "      <td>1.140480</td>\n",
       "      <td>-0.817300</td>\n",
       "      <td>-1.339318</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>505</td>\n",
       "      <td>0.629054</td>\n",
       "      <td>-1.206491</td>\n",
       "      <td>0.761926</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  time_spent  pages_viewed  basket_value  purchase  \\\n",
       "0          501    0.682273     -0.038919     -1.339318         1   \n",
       "1          502    0.040076     -1.011895      0.938511         1   \n",
       "2          503   -0.857722     -1.401086      0.644815         0   \n",
       "3          504    1.140480     -0.817300     -1.339318         1   \n",
       "4          505    0.629054     -1.206491      0.761926         1   \n",
       "\n",
       "   device_type_Desktop  device_type_Mobile  device_type_Tablet  \\\n",
       "0                 True               False               False   \n",
       "1                False                True               False   \n",
       "2                False                True               False   \n",
       "3                False               False               False   \n",
       "4                False               False                True   \n",
       "\n",
       "   device_type_Unknown  customer_type_New  customer_type_Returning  \n",
       "0                False               True                    False  \n",
       "1                False              False                     True  \n",
       "2                False              False                     True  \n",
       "3                 True               True                    False  \n",
       "4                False               True                    False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardize Features\n",
    "df = pd.read_csv(\"model_data.csv\")\n",
    "columns = ['time_spent', 'pages_viewed', 'basket_value']\n",
    "\n",
    "for column in columns:\n",
    "    df[column] = scaler.fit_transform(df[[column]])\n",
    "\n",
    "# One-hot encoding\n",
    "original_cols = df.columns\n",
    "df_encoded = pd.get_dummies(df, columns=['device_type'])\n",
    "model_feature_set = pd.get_dummies(df_encoded, columns=['customer_type'])\n",
    "\n",
    "\n",
    "model_feature_set.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a02327-d528-441c-87bf-098f9d6415e1",
   "metadata": {},
   "source": [
    "Now that all preparatory work has been done, create and train a neural network that would allow the company to predict purchases.\n",
    "\n",
    "- Using PyTorch, create a network with:\n",
    "   - At least one hidden layer with 8 units\n",
    "   - ReLU activation for hidden layer\n",
    "   - Sigmoid activation for the output layer\n",
    "- Using the prepared features in `input_model_features.csv`, train the model to predict purchases. \n",
    "- Use the validation dataset `validation_features.csv` to predict new values based on the trained model. \n",
    "- Your model should be named `purchase_model` and your output should be a DataFrame named `validation_predictions` with columns `customer_id` and `purchase`. The `purchase` column must be your predicted values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efcbda28-3c89-480d-b77a-c7f27ac759d5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 7781,
    "lastExecutedAt": 1748190896730,
    "lastExecutedByKernel": "d5bdc7bd-74a9-4a6d-987f-4fea89fe299a",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Load data\ntrain_data = pd.read_csv('input_model_features.csv')\nvalidation_data = pd.read_csv('validation_features.csv')\n\n# Verify column names\nprint(\"Training columns:\", train_data.columns.tolist())\nprint(\"Validation columns:\", validation_data.columns.tolist())\n\n# Separate features, target, and IDs\n# Training data\ncustomer_ids_train = train_data['customer_id']\nX_train = train_data.drop(columns=['purchase', 'customer_id'])  # Keep only features\ny_train = train_data['purchase']\n\n# Validation data (unseen)\ncustomer_ids_val = validation_data['customer_id']\nX_val = validation_data.drop(columns=['customer_id'])  # Keep only features\n\n# Check feature dimensions\nprint(f\"\\nTraining features shape: {X_train.shape}\")\nprint(f\"Validation features shape: {X_val.shape}\")\n\n# Split into training and validation sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X_train, y_train, test_size=0.2, random_state=42\n)\n\n# Convert to tensors\nX_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\nX_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\nX_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n\n# Create DataLoaders\ntrain_dataset = TensorDataset(X_train_tensor, y_train_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_dataset = TensorDataset(X_test_tensor, y_test_tensor)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\nval_loader = DataLoader(X_val_tensor, batch_size=32, shuffle=False)\n\n# Model definition\nclass PurchaseModel(nn.Module):\n    def __init__(self, input_size):\n        super().__init__()\n        self.layer1 = nn.Linear(input_size, 8)  # Hidden layer with 8 units\n        self.layer2 = nn.Linear(8, 1)           # Output layer\n        self.relu = nn.ReLU()                    # ReLU activation\n        self.sigmoid = nn.Sigmoid()              # Sigmoid output\n        \n    def forward(self, x):\n        x = self.relu(self.layer1(x))\n        x = self.sigmoid(self.layer2(x))\n        return x\n\n# Initialize model\ninput_size = X_train.shape[1]\nprint(f\"\\nNumber of features: {input_size}\")\npurchase_model = PurchaseModel(input_size)\n\n# Training setup\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(purchase_model.parameters(), lr=0.001)\n\n# Training loop\nprint(\"\\nStarting training...\")\nfor epoch in range(100):\n    # Training phase\n    purchase_model.train()\n    train_loss = 0.0\n    for inputs, labels in train_loader:\n        optimizer.zero_grad()\n        outputs = purchase_model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n    \n    # Validation phase\n    purchase_model.eval()\n    test_preds, test_labels = [], []\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            outputs = purchase_model(inputs)\n            test_preds.extend((outputs >= 0.5).int().tolist())\n            test_labels.extend(labels.int().tolist())\n    \n    # Calculate metrics\n    train_loss /= len(train_loader)\n    test_acc = accuracy_score(test_labels, test_preds)\n    \n    if (epoch+1) % 10 == 0:\n        print(f'Epoch {epoch+1:3d} | Train Loss: {train_loss:.4f} | Test Acc: {test_acc:.4f}')\n\n# Predict on completely unseen validation data\nprint(\"\\nGenerating predictions for validation data...\")\npurchase_model.eval()\nval_preds = []\nwith torch.no_grad():\n    for inputs in val_loader:\n        outputs = purchase_model(inputs)\n        val_preds.extend((outputs >= 0.5).int().flatten().tolist())\n\n# Create final output DataFrame\nvalidation_predictions = pd.DataFrame({\n    'customer_id': customer_ids_val,\n    'purchase': val_preds\n})\n\n# Verify output\nprint(\"\\nFirst 5 predictions:\")\nprint(validation_predictions.head())\nprint(f\"\\nPrediction distribution:\\n{validation_predictions['purchase'].value_counts()}\")\n",
    "outputsMetadata": {
     "0": {
      "height": 599,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training columns: ['customer_id', 'time_spent', 'pages_viewed', 'basket_value', 'purchase', 'device_type_Desktop', 'device_type_Mobile', 'device_type_Tablet', 'device_type_Unknown', 'customer_type_New', 'customer_type_Returning']\n",
      "Validation columns: ['customer_id', 'time_spent', 'pages_viewed', 'basket_value', 'device_type_Desktop', 'device_type_Mobile', 'device_type_Tablet', 'device_type_Unknown', 'customer_type_New', 'customer_type_Returning']\n",
      "\n",
      "Training features shape: (800, 9)\n",
      "Validation features shape: (200, 9)\n",
      "\n",
      "Number of features: 9\n",
      "\n",
      "Starting training...\n",
      "Epoch  10 | Train Loss: 0.4920 | Test Acc: 0.7688\n",
      "Epoch  20 | Train Loss: 0.4841 | Test Acc: 0.7688\n",
      "Epoch  30 | Train Loss: 0.4813 | Test Acc: 0.7688\n",
      "Epoch  40 | Train Loss: 0.4790 | Test Acc: 0.7688\n",
      "Epoch  50 | Train Loss: 0.4767 | Test Acc: 0.7688\n",
      "Epoch  60 | Train Loss: 0.4748 | Test Acc: 0.7688\n",
      "Epoch  70 | Train Loss: 0.4731 | Test Acc: 0.7688\n",
      "Epoch  80 | Train Loss: 0.4718 | Test Acc: 0.7688\n",
      "Epoch  90 | Train Loss: 0.4708 | Test Acc: 0.7688\n",
      "Epoch 100 | Train Loss: 0.4696 | Test Acc: 0.7688\n",
      "\n",
      "Generating predictions for validation data...\n",
      "\n",
      "First 5 predictions:\n",
      "   customer_id  purchase\n",
      "0         1801         1\n",
      "1         1802         1\n",
      "2         1803         1\n",
      "3         1804         1\n",
      "4         1805         1\n",
      "\n",
      "Prediction distribution:\n",
      "1    200\n",
      "Name: purchase, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('input_model_features.csv')\n",
    "validation_data = pd.read_csv('validation_features.csv')\n",
    "\n",
    "# Verify column names\n",
    "print(\"Training columns:\", train_data.columns.tolist())\n",
    "print(\"Validation columns:\", validation_data.columns.tolist())\n",
    "\n",
    "# Separate features, target, and IDs\n",
    "# Training data\n",
    "customer_ids_train = train_data['customer_id']\n",
    "X_train = train_data.drop(columns=['purchase', 'customer_id'])  # Keep only features\n",
    "y_train = train_data['purchase']\n",
    "\n",
    "# Validation data (unseen)\n",
    "customer_ids_val = validation_data['customer_id']\n",
    "X_val = validation_data.drop(columns=['customer_id'])  # Keep only features\n",
    "\n",
    "# Check feature dimensions\n",
    "print(f\"\\nTraining features shape: {X_train.shape}\")\n",
    "print(f\"Validation features shape: {X_val.shape}\")\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(X_val_tensor, batch_size=32, shuffle=False)\n",
    "\n",
    "# Model definition\n",
    "class PurchaseModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 8)  # Hidden layer with 8 units\n",
    "        self.layer2 = nn.Linear(8, 1)           # Output layer\n",
    "        self.relu = nn.ReLU()                    # ReLU activation\n",
    "        self.sigmoid = nn.Sigmoid()              # Sigmoid output\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.sigmoid(self.layer2(x))\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "input_size = X_train.shape[1]\n",
    "print(f\"\\nNumber of features: {input_size}\")\n",
    "purchase_model = PurchaseModel(input_size)\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(purchase_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "print(\"\\nStarting training...\")\n",
    "for epoch in range(100):\n",
    "    # Training phase\n",
    "    purchase_model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = purchase_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation phase\n",
    "    purchase_model.eval()\n",
    "    test_preds, test_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = purchase_model(inputs)\n",
    "            test_preds.extend((outputs >= 0.5).int().tolist())\n",
    "            test_labels.extend(labels.int().tolist())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_loss /= len(train_loader)\n",
    "    test_acc = accuracy_score(test_labels, test_preds)\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1:3d} | Train Loss: {train_loss:.4f} | Test Acc: {test_acc:.4f}')\n",
    "\n",
    "# Predict on completely unseen validation data\n",
    "print(\"\\nGenerating predictions for validation data...\")\n",
    "purchase_model.eval()\n",
    "val_preds = []\n",
    "with torch.no_grad():\n",
    "    for inputs in val_loader:\n",
    "        outputs = purchase_model(inputs)\n",
    "        val_preds.extend((outputs >= 0.5).int().flatten().tolist())\n",
    "\n",
    "# Create final output DataFrame\n",
    "validation_predictions = pd.DataFrame({\n",
    "    'customer_id': customer_ids_val,\n",
    "    'purchase': val_preds\n",
    "})\n",
    "\n",
    "# Verify output\n",
    "print(\"\\nFirst 5 predictions:\")\n",
    "print(validation_predictions.head())\n",
    "print(f\"\\nPrediction distribution:\\n{validation_predictions['purchase'].value_counts()}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
